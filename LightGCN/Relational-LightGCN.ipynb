{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset loading from txt\n",
   "id": "1229a7677039018"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:03.385441Z",
     "start_time": "2025-09-22T10:16:03.377007Z"
    }
   },
   "source": "from pathlib import Path",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:03.404615Z",
     "start_time": "2025-09-22T10:16:03.393956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_train_path = Path(\"WN18RR/train.txt\")\n",
    "_test_path = Path(\"WN18RR/test.txt\")\n",
    "_valid_path = Path(\"WN18RR/valid.txt\")"
   ],
   "id": "12d314b4e93cbd0e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:03.409645Z",
     "start_time": "2025-09-22T10:16:03.406267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(path:Path) -> list[tuple]:\n",
    "    \"\"\"\n",
    "    parses dataset path into list of tuples.\n",
    "    \"\"\"\n",
    "    datalist = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            head, relation,tail = line.strip().split(\"\\t\")\n",
    "            datalist.append((head,relation,tail))\n",
    "            \n",
    "    return datalist"
   ],
   "id": "e232fa6aa3d35460",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:03.588897Z",
     "start_time": "2025-09-22T10:16:03.411676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = load_dataset(_train_path)\n",
    "test_dataset  = load_dataset(_test_path)\n",
    "valid_dataset = load_dataset(_valid_path)"
   ],
   "id": "2c1bf010867a72ae",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Processing and Visualisation\n",
    "Understanding spread of data, edge types, nodes, etc."
   ],
   "id": "5924abe4f59e958e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:04.542372Z",
     "start_time": "2025-09-22T10:16:03.596351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "275cbdb513405226",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:04.587893Z",
     "start_time": "2025-09-22T10:16:04.543336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_entity_relation(dataset: list) -> (list, list):\n",
    "    \"\"\"\n",
    "    takes in dataset in the form of list containing triple tuples.\n",
    "    splits into sets of entities and relations, sorting them to maintain order.\n",
    "    This is done for initialising of deep learning models later.\n",
    "    :returns sorted set of entities, relations\n",
    "    \"\"\"\n",
    "    entities = sorted({h for h,_,_ in dataset }|{ t for _,_,t in dataset})\n",
    "    relations = sorted({r for _,r,_ in dataset})\n",
    "    return entities, relations\n",
    "\n",
    "entities_train, relation_train = split_entity_relation(train_dataset)\n",
    "entities_valid, relation_valid = split_entity_relation(valid_dataset)\n",
    "entities_test,  relation_test  = split_entity_relation(test_dataset)"
   ],
   "id": "b65c92cdc1a263c4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8027b38d27dff8f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:04.607554Z",
     "start_time": "2025-09-22T10:16:04.588724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"number of unique nodes in train: {len(entities_train)}\")\n",
    "print(f\"number of unique nodes in valid: {len(entities_valid)}\")\n",
    "print(f\"number of unique nodes in test : {len(entities_test)}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"number of intersecting nodes in train + valid: {len(set(entities_train) & set(entities_valid))}\"\n",
    "      f\"\\t\\tunseen percentage: \"\n",
    "      f\"{(len(set(entities_valid)) - len(set(entities_train) & set(entities_valid))) / len(set(entities_valid)) * 100:.2f}%\")\n",
    "\n",
    "print(f\"number of intersecting nodes in train + test : {len(set(entities_train) & set(entities_test))}\"\n",
    "      f\"\\t\\tunseen percentage: \"\n",
    "      f\"{(len(entities_test) - len(set(entities_train) & set(entities_test))) / len(set(entities_test)) * 100:.2f}%\")\n",
    "\n",
    "print(f\"number of intersecting nodes in valid + test : {len(set(entities_valid) & set(entities_test))}\")\n"
   ],
   "id": "8daf23d258b9471e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique nodes in train: 40559\n",
      "number of unique nodes in valid: 5173\n",
      "number of unique nodes in test : 5323\n",
      "number of intersecting nodes in train + valid: 4975\t\tunseen percentage: 3.83%\n",
      "number of intersecting nodes in train + test : 5114\t\tunseen percentage: 3.93%\n",
      "number of intersecting nodes in valid + test : 1026\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Overlaps Ensure Inference is possible\n",
    "If validation/test nodes had no overlap with training, we would have no embeddings for them, so general inferencing would become impossible.\n",
    "\n",
    "\n",
    "2.\tSpread ensures challenge:\n",
    "The few unseen nodes prevent the task from being trivial memorization. They push your model to rely on neighborhood structure, not just IDs."
   ],
   "id": "36099fb22c691dab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:04.611236Z",
     "start_time": "2025-09-22T10:16:04.608436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"number of unique edges (train): {len(set(relation_train))}\")\n",
    "print(f\"number of unique edges (valid): {len(set(relation_valid))}\")\n",
    "print(f\"number of unique edges (test) : {len(set(relation_test))} \")"
   ],
   "id": "8a8f36b13f10255f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique edges (train): 11\n",
      "number of unique edges (valid): 11\n",
      "number of unique edges (test) : 11 \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This is correct as any models will not be able to infer based on an unseen edge type.\n",
    "\n",
    "Hence, having the same number of unique edge types ensure proper inferencing. "
   ],
   "id": "3de36a58a8b8f4b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:16:04.614511Z",
     "start_time": "2025-09-22T10:16:04.611969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "_random_sample_entity = entities_train[random.randint(0, len(entities_train))]\n",
    "print(f\"sample of entity: {_random_sample_entity}\")\n",
    "print(f\"type of entity  : {type(_random_sample_entity)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "_random_sample_relation = relation_train[random.randint(0, len(relation_train))]\n",
    "print(f\"sample of relation: {_random_sample_relation}\")\n",
    "print(f\"type of relation  : {type(_random_sample_relation)}\")\n",
    "print(\"\\nWe want to map these strings to integer indexes for training as lightGCN expects node IDs as continuous integers.\")"
   ],
   "id": "6a1d892ac90717c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample of entity: 01858441\n",
      "type of entity  : <class 'str'>\n",
      "\n",
      "\n",
      "sample of relation: _also_see\n",
      "type of relation  : <class 'str'>\n",
      "\n",
      "We want to map these strings to integer indexes for training as lightGCN expects node IDs as continuous integers.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:44:51.700872Z",
     "start_time": "2025-09-22T10:44:51.663771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_entity_values(unmapped_values: list) -> dict[str, int]:\n",
    "    return {val: i for i, val in enumerate(unmapped_values)}\n",
    "\n",
    "print(\"Mapping of entities to consecutive values\")\n",
    "all_entities = sorted(set(entities_test + entities_train + entities_valid))\n",
    "all_entities_mapped = map_entity_values(all_entities)\n",
    "print(len(all_entities_mapped))\n"
   ],
   "id": "17a19dd5bcb63229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of entities to consecutive values\n",
      "40943\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prepare Data to Pass into LightGCN\n",
    "\n",
    "```LightGCN``` :expects 2 types of data when using hetero:\n",
    "\n",
    "\n",
    "```x_dict```   : which is the dictionary of embedding related to that node (trainable)\n",
    "\n",
    "\n",
    "```edge_index_dict```  : which is the ```{('entity', relation, 'entity'): tensor[[src],[dst]]}``` \n",
    " "
   ],
   "id": "5d5e07fe58094f09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "we also add new inverse type of relation on top of the 11 that already exists.\n",
    "this allows for information to be passed around which originally didnt.\n",
    "A -> B is one way, and there should be an inverse relationship (or some information) which is missed out."
   ],
   "id": "d5262f48ffc73d04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T11:15:42.957663Z",
     "start_time": "2025-09-22T11:15:42.742418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['entity'].num_nodes = len(all_entities_mapped)\n",
    "\n",
    "# create truple\n",
    "def build_edge_index_dict(\n",
    "        dataset: List[tuple[str, str, str]],  # list of (h, r, t) triples\n",
    "        mapped_entity: Dict[str, int],\n",
    "        add_reverse: bool = True\n",
    ") -> Dict[Tuple[str, str, str], torch.Tensor]:\n",
    "    \n",
    "    edge_index_dict = {}\n",
    "    relation_dict = defaultdict(list)\n",
    "    # adds relation : (src, dst)\n",
    "    for h,r,t in dataset:\n",
    "        relation_dict[r].append((mapped_entity[h],mapped_entity[t]))\n",
    "\n",
    "        # adds relation : (dst, src)\n",
    "        if add_reverse:\n",
    "            reverse_r = r+'_inv'\n",
    "            relation_dict[reverse_r].append((mapped_entity[t],mapped_entity[h]))\n",
    "\n",
    "    for r,v in relation_dict.items():\n",
    "        # v is the [(src,dst)]\n",
    "        src_list, dst_list = [], []\n",
    "         \n",
    "        for src,dst in v:\n",
    "            src_list.append(src)\n",
    "            dst_list.append(dst)\n",
    "        src_tensor = torch.Tensor(src_list)\n",
    "        dst_tensor = torch.Tensor(dst_list)\n",
    "        src_dst_tensor = torch.vstack((src_tensor,dst_tensor))\n",
    "        \n",
    "        edge_index_dict[('entity',r,'entity')] = src_dst_tensor\n",
    "        \n",
    "    \n",
    "    return edge_index_dict    \n",
    "        \n",
    "\n",
    "edge_index_dict = build_edge_index_dict(train_dataset, all_entities_mapped, True)\n",
    "\n",
    "for rel, edge_index in edge_index_dict.items():\n",
    "    data[rel].edge_index = edge_index"
   ],
   "id": "96285728764b0ef6",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T11:00:03.098712Z",
     "start_time": "2025-09-22T11:00:03.094064Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "4fa80df2bcd0189f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  entity={ num_nodes=40943 },\n",
       "  (entity, _hypernym, entity)={ edge_index=[2, 34796] },\n",
       "  (entity, _hypernym_inv, entity)={ edge_index=[2, 34796] },\n",
       "  (entity, _derivationally_related_form, entity)={ edge_index=[2, 29715] },\n",
       "  (entity, _derivationally_related_form_inv, entity)={ edge_index=[2, 29715] },\n",
       "  (entity, _instance_hypernym, entity)={ edge_index=[2, 2921] },\n",
       "  (entity, _instance_hypernym_inv, entity)={ edge_index=[2, 2921] },\n",
       "  (entity, _also_see, entity)={ edge_index=[2, 1299] },\n",
       "  (entity, _also_see_inv, entity)={ edge_index=[2, 1299] },\n",
       "  (entity, _member_meronym, entity)={ edge_index=[2, 7402] },\n",
       "  (entity, _member_meronym_inv, entity)={ edge_index=[2, 7402] },\n",
       "  (entity, _synset_domain_topic_of, entity)={ edge_index=[2, 3116] },\n",
       "  (entity, _synset_domain_topic_of_inv, entity)={ edge_index=[2, 3116] },\n",
       "  (entity, _has_part, entity)={ edge_index=[2, 4816] },\n",
       "  (entity, _has_part_inv, entity)={ edge_index=[2, 4816] },\n",
       "  (entity, _member_of_domain_usage, entity)={ edge_index=[2, 629] },\n",
       "  (entity, _member_of_domain_usage_inv, entity)={ edge_index=[2, 629] },\n",
       "  (entity, _member_of_domain_region, entity)={ edge_index=[2, 923] },\n",
       "  (entity, _member_of_domain_region_inv, entity)={ edge_index=[2, 923] },\n",
       "  (entity, _verb_group, entity)={ edge_index=[2, 1138] },\n",
       "  (entity, _verb_group_inv, entity)={ edge_index=[2, 1138] },\n",
       "  (entity, _similar_to, entity)={ edge_index=[2, 80] },\n",
       "  (entity, _similar_to_inv, entity)={ edge_index=[2, 80] }\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "now that we have created and preped the data that will be used for training,\n",
    "we will create embedding for each node that will be trainable."
   ],
   "id": "cd39e90836db9ea4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T11:33:19.473788Z",
     "start_time": "2025-09-22T11:33:19.409822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "FEATURE_SIZE = 64\n",
    "embedding_matrix = torch.nn.Embedding(len(all_entities_mapped), FEATURE_SIZE)\n",
    "nn.init.xavier_uniform_(embedding_matrix.weight)"
   ],
   "id": "98dc28c7edf05bdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0091,  0.0020, -0.0089,  ..., -0.0081, -0.0003,  0.0105],\n",
       "        [ 0.0114, -0.0030,  0.0113,  ...,  0.0075, -0.0035,  0.0006],\n",
       "        [-0.0097,  0.0097,  0.0074,  ...,  0.0043,  0.0011,  0.0040],\n",
       "        ...,\n",
       "        [-0.0121,  0.0009, -0.0045,  ...,  0.0053, -0.0114, -0.0097],\n",
       "        [-0.0005, -0.0017, -0.0017,  ..., -0.0057,  0.0111,  0.0085],\n",
       "        [ 0.0114,  0.0028,  0.0108,  ...,  0.0002,  0.0118, -0.0076]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LightGCN Model definition",
   "id": "e22d21d99c416c82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 20,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import LGConv, to_hetero\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n"
   ],
   "id": "52e37597dc29f1d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311 WN18RR",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
