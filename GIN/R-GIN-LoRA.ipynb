{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-18T07:56:43.218509Z",
     "start_time": "2025-10-18T07:56:43.207694Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional, Dict, Any\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    _HAS_SK = True\n",
    "except Exception:\n",
    "    _HAS_SK = False\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class RelationalLoRAGINConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Relational LoRA adapter for GIN-style message passing.\n",
    "\n",
    "    Message:\n",
    "        base:    W x_j\n",
    "        adapter: (A_r B_r^T) x_j               with rank k << d\n",
    "        total:   W x_j + scale * (A_r B_r^T) x_j\n",
    "\n",
    "    Update (GIN):\n",
    "        x_i' = MLP( (1 + eps) * x_i + sum_j message )\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): node feature dimensionality d.\n",
    "        num_relations (int): number of relation types |R|.\n",
    "        rank (int): LoRA rank k (e.g., 4–16).\n",
    "        hidden_layers (int): depth of the node MLP inside the conv.\n",
    "        train_eps (bool): whether epsilon in GIN update is learnable.\n",
    "        adapter_scale (float): multiplicative scale on adapter path.\n",
    "        bias (bool): bias for the shared linear map W.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            emb_dim: int,\n",
    "            num_relations: int,\n",
    "            rank: int = 8,\n",
    "            hidden_layers: int = 2,\n",
    "            train_eps: bool = True,\n",
    "            adapter_scale: float = 1.0,\n",
    "            bias: bool = False,\n",
    "    ):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.emb_dim = emb_dim\n",
    "        self.rank = rank\n",
    "        self.adapter_scale = adapter_scale\n",
    "\n",
    "        # GIN epsilon\n",
    "        self.eps = (\n",
    "            nn.Parameter(torch.zeros(1))\n",
    "            if train_eps else nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        )\n",
    "\n",
    "        # Shared linear message transform\n",
    "        self.W = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        nn.init.xavier_uniform_(self.W.weight)\n",
    "\n",
    "        # Relation-specific low-rank adapters (stored as embeddings)\n",
    "        # A_r, B_r ∈ R^{d×k} are stored flattened per-relation.\n",
    "        self.A = nn.Embedding(num_relations, emb_dim * rank)  # [|R|, d*k]\n",
    "        self.B = nn.Embedding(num_relations, emb_dim * rank)  # [|R|, d*k]\n",
    "        nn.init.xavier_uniform_(self.A.weight)\n",
    "        nn.init.xavier_uniform_(self.B.weight)\n",
    "\n",
    "        # Node MLP (same output dim as input, like GIN)\n",
    "        layers = [nn.Linear(emb_dim, emb_dim * 2), nn.ReLU()]\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers += [nn.Linear(emb_dim * 2, emb_dim * 2), nn.ReLU()]\n",
    "        layers += [nn.Linear(emb_dim * 2, emb_dim)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x: torch.Tensor,               # [N, d]\n",
    "            edge_index: torch.Tensor,      # [2, E]\n",
    "            edge_type: torch.Tensor,       # [E]\n",
    "    ) -> torch.Tensor:\n",
    "        return self.propagate(edge_index, x=x, edge_type=edge_type)\n",
    "\n",
    "    def message(\n",
    "            self,\n",
    "            x_j: torch.Tensor,             # [E, d] neighbor features\n",
    "            edge_type: torch.Tensor,       # [E] relation id per edge\n",
    "    ) -> torch.Tensor:\n",
    "        # Shared message\n",
    "        base = self.W(x_j)  # [E, d]\n",
    "\n",
    "        # Low-rank adapter per relation\n",
    "        A_flat = self.A(edge_type)                       # [E, d*k]\n",
    "        B_flat = self.B(edge_type)                       # [E, d*k]\n",
    "        A = A_flat.view(-1, self.emb_dim, self.rank)     # [E, d, k]\n",
    "        B = B_flat.view(-1, self.emb_dim, self.rank)     # [E, d, k]\n",
    "\n",
    "        # Compute (A_r B_r^T) x_j efficiently:\n",
    "        #   Bj = B_r^T x_j  -> [E, k]\n",
    "        Bj = torch.einsum('edk,ed->ek', B, x_j)\n",
    "        #   adapter = A_r Bj -> [E, d]\n",
    "        adapter = torch.einsum('edk,ek->ed', A, Bj)\n",
    "\n",
    "        return base + self.adapter_scale * adapter\n",
    "\n",
    "    def update(self, aggr_out: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.mlp((1.0 + self.eps) * x + aggr_out)\n",
    "\n",
    "\n",
    "class RelationalLoRAGINEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacks multiple RelationalLoRAGINConv layers over a learned node embedding table.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_nodes: int,\n",
    "            num_relations: int,\n",
    "            emb_dim: int = 128,\n",
    "            num_layers: int = 3,\n",
    "            hidden_layers: int = 2,\n",
    "            dropout: float = 0.1,\n",
    "            rank: int = 8,\n",
    "            adapter_scale: float = 1.0,\n",
    "            train_eps: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(num_nodes, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.embed.weight)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            RelationalLoRAGINConv(\n",
    "                emb_dim=emb_dim,\n",
    "                num_relations=num_relations,\n",
    "                rank=rank,\n",
    "                hidden_layers=hidden_layers,\n",
    "                train_eps=train_eps,\n",
    "                adapter_scale=adapter_scale,\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, edge_index: torch.Tensor, edge_type: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embed.weight                        # [N, d]\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_type)       # [N, d]\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T07:56:43.879537Z",
     "start_time": "2025-10-18T07:56:43.862031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _fmt_ts(dt: datetime) -> str:\n",
    "    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def _fmt(x):\n",
    "    try:\n",
    "        return f\"{float(x):.4f}\"\n",
    "    except Exception:\n",
    "        return \"nan\"\n",
    "\n",
    "def print_comparison_report(\n",
    "        title: str,\n",
    "        left_name: str, left_result: Dict[str, Any],\n",
    "        right_name: str, right_result: Dict[str, Any],\n",
    "        save_path: Optional[str | Path] = None,\n",
    "):\n",
    "    ts = _fmt_ts(datetime.now())\n",
    "\n",
    "    def block(name, res):\n",
    "        best = res[\"best\"]; hist = res[\"history\"]\n",
    "        best_auc = max((h.get(\"val_auc\", float(\"nan\")) for h in hist), default=float(\"nan\"))\n",
    "        total_epochs = res.get(\"epochs_trained\", len(hist))\n",
    "\n",
    "        lines = []\n",
    "        lines.append(f\"{name} Training History\")\n",
    "        lines.append(\"=\" * 60)\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"Best Validation AUC: {_fmt(best_auc)}\")\n",
    "        lines.append(f\"Total Epochs Trained: {total_epochs}\")\n",
    "        lines.append(f\"Early Stopping Best Score: {_fmt(best.get('Hits@10'))} (Hits@10 at epoch {best.get('epoch')})\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"-\" * 90)\n",
    "        lines.append(f\"{'Epoch':<8} {'Train Loss':<14} {'Val AUC':<12} {'Val H@1':<12} {'Val H@5':<12} {'Val H@10':<12}\")\n",
    "        lines.append(\"-\" * 90)\n",
    "        for rec in hist:\n",
    "            e = rec.get(\"epoch\")\n",
    "            lines.append(\n",
    "                f\"{e:<8} \"\n",
    "                f\"{_fmt(rec.get('train_loss')):<14} \"\n",
    "                f\"{_fmt(rec.get('val_auc')):<12} \"\n",
    "                f\"{_fmt(rec.get('val_hits1')):<12} \"\n",
    "                f\"{_fmt(rec.get('val_hits5')):<12} \"\n",
    "                f\"{_fmt(rec.get('val_hits10')):<12}\"\n",
    "            )\n",
    "        lines.append(\"\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    out = []\n",
    "    out.append(f\"{title} - {ts}\")\n",
    "    out.append(\"=\" * 80)\n",
    "    out.append(\"\")\n",
    "    out.append(block(left_name, left_result))\n",
    "    out.append(block(right_name, right_result))\n",
    "\n",
    "    # Best-at-a-glance\n",
    "    out.append(\"Best Validation Metrics Summary\")\n",
    "    out.append(\"=\" * 60)\n",
    "    for name, res in [(left_name, left_result), (right_name, right_result)]:\n",
    "        b = res[\"best\"]\n",
    "        out.append(\n",
    "            f\"{name}: \"\n",
    "            f\"AUC={_fmt(b.get('AUC'))} | \"\n",
    "            f\"H@1={_fmt(b.get('Hits@1'))} | \"\n",
    "            f\"H@5={_fmt(b.get('Hits@5'))} | \"\n",
    "            f\"H@10={_fmt(b.get('Hits@10'))} \"\n",
    "            f\"(epoch {b.get('epoch')})\"\n",
    "        )\n",
    "    out.append(\"\")\n",
    "\n",
    "    report = \"\\n\".join(out)\n",
    "    print(report)\n",
    "\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\n✅ Comparison report saved to: {save_path.resolve()}\")\n",
    "\n",
    "\n",
    "def print_training_report(\n",
    "        model_name: str,\n",
    "        result: Dict[str, Any],\n",
    "        header_title: str = \"Model Training Results\",\n",
    "        save_path: Optional[str | Path] = None,\n",
    "):\n",
    "    ts = _fmt_ts(result.get(\"end_time\", datetime.now()))\n",
    "    best = result[\"best\"]\n",
    "    history = result[\"history\"]\n",
    "    total_epochs = result.get(\"epochs_trained\", len(history))\n",
    "    best_auc = max((h.get(\"val_auc\", float(\"nan\")) for h in history), default=float(\"nan\"))\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"{header_title} - {ts}\")\n",
    "    lines.append(\"=\" * 80)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"{model_name} Training History\")\n",
    "    lines.append(\"=\" * 60)\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"Best Validation AUC: {_fmt(best_auc)}\")\n",
    "    lines.append(f\"Total Epochs Trained: {total_epochs}\")\n",
    "    lines.append(f\"Early Stopping Best Score: {_fmt(best.get('Hits@10'))} (Hits@10 at epoch {best.get('epoch')})\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"-\" * 90)\n",
    "    lines.append(f\"{'Epoch':<8} {'Train Loss':<14} {'Val AUC':<12} {'Val H@1':<12} {'Val H@5':<12} {'Val H@10':<12}\")\n",
    "    lines.append(\"-\" * 90)\n",
    "\n",
    "    for rec in history:\n",
    "        e = rec.get(\"epoch\")\n",
    "        lines.append(\n",
    "            f\"{e:<8} \"\n",
    "            f\"{_fmt(rec.get('train_loss')):<14} \"\n",
    "            f\"{_fmt(rec.get('val_auc')):<12} \"\n",
    "            f\"{_fmt(rec.get('val_hits1')):<12} \"\n",
    "            f\"{_fmt(rec.get('val_hits5')):<12} \"\n",
    "            f\"{_fmt(rec.get('val_hits10')):<12}\"\n",
    "        )\n",
    "\n",
    "    lines.append(\"\")\n",
    "    report_text = \"\\n\".join(lines)\n",
    "\n",
    "    print(report_text)\n",
    "\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report_text)\n",
    "        print(f\"\\n✅ Report saved to: {save_path.resolve()}\")\n",
    "\n",
    "\n",
    "# ---------- Build edge_index and edge_type from the *train* split ----------\n",
    "def build_edge_index_and_type_from_typed_dm(dm) -> tuple[torch.LongTensor, torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        edge_index: [2, E] directed edges\n",
    "        edge_type:  [E]    relation id per edge (aligned with edge_index columns)\n",
    "    Uses dm._train_triples directly (already contains reverse triples if add_reverse=True).\n",
    "    \"\"\"\n",
    "    assert hasattr(dm, \"_train_triples\"), \"KGDataModuleTyped expected.\"\n",
    "    triples = dm._train_triples  # [N, 3] (h, r, t), torch.long\n",
    "    if triples.numel() == 0:\n",
    "        return torch.empty(2, 0, dtype=torch.long), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    h = triples[:, 0]\n",
    "    r = triples[:, 1]\n",
    "    t = triples[:, 2]\n",
    "\n",
    "    edge_index = torch.stack([h, t], dim=0).contiguous()  # directed edges h->t\n",
    "    edge_type = r.contiguous()                             # relation per edge\n",
    "    return edge_index, edge_type\n",
    "\n",
    "\n",
    "# ---------- Typed negative sampling (corrupt head/tail, keep relation) ----------\n",
    "@torch.no_grad()\n",
    "def sample_negatives_typed(triples: torch.Tensor, num_entities: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    1:1 negatives per positive (half head-corrupt, half tail-corrupt).\n",
    "    Input triples: [B,3] (h, r, t)\n",
    "    Output triples: [B,3] negatives (h', r, t) or (h, r, t')\n",
    "    \"\"\"\n",
    "    B = triples.size(0)\n",
    "    device = triples.device\n",
    "    neg = triples.clone()\n",
    "    flip = torch.rand(B, device=device) < 0.5\n",
    "    rand_ents = torch.randint(0, num_entities, (B,), device=device)\n",
    "\n",
    "    # corrupt head\n",
    "    neg[flip, 0] = rand_ents[flip]\n",
    "    # corrupt tail\n",
    "    neg[~flip, 2] = rand_ents[~flip]\n",
    "    return neg\n",
    "\n",
    "\n",
    "# ---------- DistMult decoder for typed link prediction ----------\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    score(h, r, t) = <e_h, w_r, e_t> = sum_d e_h[d] * w_r[d] * e_t[d]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_relations: int, dim: int):\n",
    "        super().__init__()\n",
    "        self.rel = torch.nn.Embedding(num_relations, dim)\n",
    "        torch.nn.init.xavier_uniform_(self.rel.weight)\n",
    "\n",
    "    def forward(self, z: torch.Tensor, triples: torch.LongTensor) -> torch.Tensor:\n",
    "        # triples: [B,3] (h, r, t)\n",
    "        h, r, t = triples[:, 0], triples[:, 1], triples[:, 2]\n",
    "        e_h, e_t, w_r = z[h], z[t], self.rel(r)\n",
    "        return (e_h * w_r * e_t).sum(dim=1)  # [B]\n",
    "\n",
    "class DotProductDecoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    score(h, r, t) = <e_h, e_t> (relation is ignored)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z: torch.Tensor, triples: torch.LongTensor) -> torch.Tensor:\n",
    "        h, t = triples[:, 0], triples[:, 2]\n",
    "        return (z[h] * z[t]).sum(dim=1)  # [B]\n",
    "\n",
    "def scores_for_candidates(\n",
    "        decoder: torch.nn.Module,\n",
    "        z: torch.Tensor,\n",
    "        h: torch.Tensor,                # [B]\n",
    "        r: torch.Tensor,                # [B]\n",
    "        cand_t: torch.Tensor,           # [B, K]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns [B, K] scores for candidates.\n",
    "    Fast path for DistMult; generic path for DotProduct.\n",
    "    \"\"\"\n",
    "    if isinstance(decoder, DistMultDecoder):\n",
    "        e_h = z[h]                       # [B, d]\n",
    "        w_r = decoder.rel(r)            # [B, d]\n",
    "        e_c = z[cand_t]                 # [B, K, d]\n",
    "        s = ((e_h * w_r).unsqueeze(1) * e_c).sum(dim=2)  # [B, K]\n",
    "        return s\n",
    "    else:\n",
    "        # generic: build triples and call decoder\n",
    "        B, K = cand_t.shape\n",
    "        h_rep = h.view(B, 1).expand(B, K)\n",
    "        r_rep = r.view(B, 1).expand(B, K)  # unused by dot, but fine for API\n",
    "        triples = torch.stack([h_rep, r_rep, cand_t], dim=2).reshape(-1, 3)  # [B*K,3]\n",
    "        s = decoder(z, triples).view(B, K)\n",
    "        return s"
   ],
   "id": "a9b62d3ca2c8de17",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T07:56:44.025304Z",
     "start_time": "2025-10-18T07:56:44.018101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_metrics_typed(\n",
    "        encoder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,\n",
    "        edge_index: torch.Tensor,\n",
    "        edge_type: torch.Tensor,\n",
    "        loader: Optional[DataLoader],\n",
    "        num_entities: int,\n",
    "        device: torch.device,\n",
    "        show_tqdm: bool = False,\n",
    ") -> Dict[str, float]:\n",
    "    if loader is None:\n",
    "        return {\"AUC\": float(\"nan\"), \"Hits@1\": float(\"nan\"), \"Hits@5\": float(\"nan\"), \"Hits@10\": float(\"nan\")}\n",
    "\n",
    "    encoder.eval(); decoder.eval()\n",
    "    z = encoder(edge_index.to(device), edge_type.to(device))  # [N, d]\n",
    "\n",
    "    # --- AUC ---\n",
    "    all_scores, all_labels = [], []\n",
    "    it_auc = loader if not show_tqdm else tqdm(loader, leave=False, desc=\"Eval AUC (typed)\")\n",
    "    for pos, _ in it_auc:\n",
    "        pos = pos.to(device)\n",
    "        neg = sample_negatives_typed(pos, num_entities)\n",
    "\n",
    "        s_pos = decoder(z, pos)\n",
    "        s_neg = decoder(z, neg)\n",
    "\n",
    "        all_scores.append(torch.cat([s_pos, s_neg]).detach().cpu().numpy())\n",
    "        all_labels.append(np.concatenate([np.ones(len(s_pos)), np.zeros(len(s_neg))]))\n",
    "\n",
    "    scores = np.concatenate(all_scores) if len(all_scores) > 0 else np.array([])\n",
    "    labels = np.concatenate(all_labels) if len(all_labels) > 0 else np.array([])\n",
    "    if _HAS_SK and len(scores) > 0:\n",
    "        auc = float(roc_auc_score(labels, scores))\n",
    "    else:\n",
    "        auc = float(\"nan\") if len(scores) == 0 else float((scores[labels == 1].mean() > scores[labels == 0].mean()))\n",
    "\n",
    "    # --- Hits@K (tail ranking) ---\n",
    "    hits1 = hits5 = hits10 = 0\n",
    "    trials = 0\n",
    "    it_hits = loader if not show_tqdm else tqdm(loader, leave=False, desc=\"Eval Hits (tail)\")\n",
    "    for pos, _ in it_hits:\n",
    "        pos = pos.to(device)\n",
    "        B = pos.size(0)\n",
    "        h, r, t_true = pos[:, 0], pos[:, 1], pos[:, 2]\n",
    "\n",
    "        rand_t = torch.randint(0, num_entities, (B, 99), device=device)\n",
    "        cand_t = torch.cat([t_true.view(-1, 1), rand_t], dim=1)  # [B,100]\n",
    "\n",
    "        s = scores_for_candidates(decoder, z, h, r, cand_t)  # [B,100]\n",
    "        ranks = s.argsort(dim=1, descending=True)\n",
    "        true_positions = torch.nonzero(ranks == 0, as_tuple=False)[:, 1] + 1  # 1-based\n",
    "        hits1  += (true_positions <= 1).sum().item()\n",
    "        hits5  += (true_positions <= 5).sum().item()\n",
    "        hits10 += (true_positions <= 10).sum().item()\n",
    "        trials += B\n",
    "\n",
    "    return {\n",
    "        \"AUC\": auc,\n",
    "        \"Hits@1\": hits1 / max(trials, 1),\n",
    "        \"Hits@5\": hits5 / max(trials, 1),\n",
    "        \"Hits@10\": hits10 / max(trials, 1),\n",
    "    }"
   ],
   "id": "cefa9f3214d603cd",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T07:56:44.333255Z",
     "start_time": "2025-10-18T07:56:44.319243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def _safe_filename(s: str) -> str:\n",
    "    # replace characters that can be annoying in shells/IDEs\n",
    "    return re.sub(r'[^A-Za-z0-9._\\-=/]', '_', s)\n",
    "\n",
    "def train_linkpred_typed(\n",
    "        encoder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,                 # DistMultDecoder (or another typed decoder)\n",
    "        dm,                                       # KGDataModuleTyped\n",
    "        epochs: int = 100,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 1e-4,\n",
    "        patience: int = 10,\n",
    "        device: Optional[torch.device] = None,\n",
    "        show_tqdm: bool = True,\n",
    "        save_best_path: Optional[str | Path] = None,\n",
    "        save_on_improve: bool = True,\n",
    "        hparams: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    # Optimizer only over encoder + decoder\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Build typed graph from *train* split\n",
    "    edge_index, edge_type = build_edge_index_and_type_from_typed_dm(dm)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_type  = edge_type.to(device)\n",
    "\n",
    "    train_loader = dm.train_loader()\n",
    "    val_loader   = dm.val_loader()\n",
    "    num_entities = len(dm.ent2id)\n",
    "    num_relations = len(dm.rel2id)\n",
    "\n",
    "    # hparams\n",
    "    auto_hparams: Dict[str, Any] = {\n",
    "        \"model_name\": f\"{encoder.__class__.__name__}+{decoder.__class__.__name__}\",\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"patience\": patience,\n",
    "        \"typed_graph\": True,\n",
    "        \"batch_size\": getattr(dm, \"batch_size\", None),\n",
    "        \"add_reverse\": getattr(dm, \"add_reverse\", None),\n",
    "        \"reverse_relation_strategy\": getattr(dm, \"reverse_relation_strategy\", None),\n",
    "        \"num_nodes\": len(dm.ent2id),\n",
    "        \"num_relations\": num_relations,\n",
    "        \"enc_emb_dim\": getattr(getattr(encoder, \"embed\", None), \"embedding_dim\", None),\n",
    "        \"enc_num_layers\": len(getattr(encoder, \"convs\", [])),\n",
    "        \"decoder\": decoder.__class__.__name__,\n",
    "    }\n",
    "    run_hparams = {**auto_hparams, **(hparams or {})}\n",
    "\n",
    "    history = []\n",
    "    best = {\"epoch\": 0, \"AUC\": -1.0, \"Hits@1\": 0.0, \"Hits@5\": 0.0, \"Hits@10\": 0.0}\n",
    "    patience_ctr = 0\n",
    "    best_state = None\n",
    "\n",
    "    save_best_path = Path(save_best_path) if save_best_path else None\n",
    "    if save_best_path:\n",
    "        save_best_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    epoch_iter = range(1, epochs + 1)\n",
    "    if show_tqdm:\n",
    "        epoch_iter = tqdm(epoch_iter, desc=\"Epochs (typed)\")\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        encoder.train(); decoder.train()\n",
    "        running_loss = 0.0\n",
    "        running_n = 0\n",
    "\n",
    "        batch_iter = train_loader\n",
    "        if show_tqdm:\n",
    "            batch_iter = tqdm(train_loader, leave=False, desc=f\"Train {epoch}\")\n",
    "\n",
    "        # Precompute node embeddings once per epoch for efficiency\n",
    "        z = encoder(edge_index, edge_type)  # [N, d]\n",
    "\n",
    "        for pos, _ in batch_iter:\n",
    "            pos = pos.to(device)\n",
    "            neg = sample_negatives_typed(pos, num_entities).to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # recompute embeddings for THIS batch so we have a fresh graph\n",
    "            z = encoder(edge_index, edge_type)              # <— moved inside\n",
    "\n",
    "            s_pos = decoder(z, pos)\n",
    "            s_neg = decoder(z, neg)\n",
    "\n",
    "            scores = torch.cat([s_pos, s_neg], dim=0)\n",
    "            labels = torch.cat([torch.ones_like(s_pos), torch.zeros_like(s_neg)], dim=0)\n",
    "            loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_n += 1\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(encoder.parameters()) + list(decoder.parameters()), max_norm=1.0\n",
    "            )\n",
    "            opt.step()\n",
    "\n",
    "            if show_tqdm:\n",
    "                batch_iter.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        train_loss = running_loss / max(running_n, 1)\n",
    "\n",
    "        # Validation (fresh z to reflect updated encoder)\n",
    "        val_metrics = evaluate_metrics_typed(\n",
    "            encoder, decoder, edge_index, edge_type, val_loader, num_entities, device, show_tqdm=show_tqdm\n",
    "        )\n",
    "        if show_tqdm:\n",
    "            tqdm.write(f\"Epoch {epoch:03d} | loss={train_loss:.4f} | \"\n",
    "                       f\"AUC={val_metrics['AUC']:.4f} | \"\n",
    "                       f\"H@1={val_metrics['Hits@1']:.4f} | \"\n",
    "                       f\"H@5={val_metrics['Hits@5']:.4f} | \"\n",
    "                       f\"H@10={val_metrics['Hits@10']:.4f}\")\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"val_auc\": float(val_metrics[\"AUC\"]),\n",
    "            \"val_hits1\": float(val_metrics[\"Hits@1\"]),\n",
    "            \"val_hits5\": float(val_metrics[\"Hits@5\"]),\n",
    "            \"val_hits10\": float(val_metrics[\"Hits@10\"]),\n",
    "        })\n",
    "        # Early stopping on Hits@10\n",
    "        if val_metrics[\"Hits@10\"] > best[\"Hits@10\"]:\n",
    "            best.update({\"epoch\": epoch, **val_metrics})\n",
    "            best_state = {\n",
    "                \"encoder\": {k: v.detach().cpu() for k, v in encoder.state_dict().items()},\n",
    "                \"decoder\": {k: v.detach().cpu() for k, v in decoder.state_dict().items()},\n",
    "            }\n",
    "            patience_ctr = 0\n",
    "\n",
    "            if save_best_path and save_on_improve:\n",
    "\n",
    "                if save_best_path:\n",
    "                    save_best_path = Path(_safe_filename(str(save_best_path)))\n",
    "                    save_best_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"encoder_state_dict\": best_state[\"encoder\"],\n",
    "                        \"decoder_state_dict\": best_state[\"decoder\"],\n",
    "                        \"epoch\": epoch,\n",
    "                        \"best_metrics\": best,\n",
    "                        \"history\": history,\n",
    "                        \"hparams\": run_hparams,\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                    },\n",
    "                    save_best_path,\n",
    "                )\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                if show_tqdm:\n",
    "                    tqdm.write(f\"Early stopping at epoch {epoch} (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "    # Restore best\n",
    "    end_time = datetime.now()\n",
    "    if best_state is not None:\n",
    "        encoder.load_state_dict(best_state[\"encoder\"])\n",
    "        decoder.load_state_dict(best_state[\"decoder\"])\n",
    "        if show_tqdm:\n",
    "            tqdm.write(f\"Restored best model from epoch {best['epoch']} | \"\n",
    "                       f\"AUC={best['AUC']:.4f} | Hits@10={best['Hits@10']:.4f}\")\n",
    "\n",
    "        # If you prefer single save at end:\n",
    "        if save_best_path and not save_on_improve:\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"encoder_state_dict\": best_state[\"encoder\"],\n",
    "                    \"decoder_state_dict\": best_state[\"decoder\"],\n",
    "                    \"epoch\": best[\"epoch\"],\n",
    "                    \"best_metrics\": best,\n",
    "                    \"history\": history,\n",
    "                    \"hparams\": run_hparams,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                },\n",
    "                save_best_path,\n",
    "            )\n",
    "            if show_tqdm:\n",
    "                tqdm.write(f\"Saved final best checkpoint to {save_best_path}\")\n",
    "\n",
    "    return {\n",
    "        \"best\": best,\n",
    "        \"history\": history,\n",
    "        \"epochs_trained\": history[-1][\"epoch\"] if history else 0,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "        \"checkpoint_path\": str(save_best_path) if save_best_path else None,\n",
    "        \"hparams\": run_hparams,\n",
    "    }"
   ],
   "id": "f15f95b68ed35988",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-18T07:56:58.429847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1) LoRA R-GIN + DistMult ---\n",
    "lora_rank = 8           # try 4–16; 8 is a good start for d=128\n",
    "adapter_scale = 1.0     # you can anneal or tune this (e.g., 0.5–2.0)\n",
    "\n",
    "dataset = \"WN18RR\"\n",
    "num_layers, hidden_layers, emb_dim = 3,3,128\n",
    "\n",
    "# --- Dataset setup: defines dm_typed, num_nodes, num_relations ---\n",
    "from pathlib import Path\n",
    "from dataset_loader import KGDataModuleTyped\n",
    "\n",
    "dataset = \"WN18RR\"  # or \"FB15k-237\", etc.\n",
    "train_p = Path(\"../WN18RR/train.txt\")\n",
    "valid_p = Path(\"../WN18RR/valid.txt\")\n",
    "test_p  = Path(\"../WN18RR/test.txt\")\n",
    "\n",
    "# Create the typed KG datamodule\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p,\n",
    "    valid_p,\n",
    "    test_p,\n",
    "    batch_size=1024,              # or whatever you use\n",
    "    add_reverse=True,             # keep as in your code\n",
    "    reverse_relation_strategy=\"duplicate_rel\",  # creates separate reverse relation ids\n",
    "    num_workers=2                 # optional\n",
    ")\n",
    "\n",
    "# Entity and relation counts for your embedding tables\n",
    "num_nodes = len(dm_typed.ent2id)     # number of entities (nodes)\n",
    "num_relations = len(dm_typed.rel2id) # number of relation types (including reverse if added)\n",
    "\n",
    "print(f\"Entities: {num_nodes} | Relations: {num_relations}\")\n",
    "\n",
    "enc_lora = RelationalLoRAGINEncoder(\n",
    "    num_nodes=num_nodes,\n",
    "    num_relations=num_relations,\n",
    "    emb_dim=emb_dim,\n",
    "    num_layers=num_layers,\n",
    "    hidden_layers=hidden_layers,\n",
    "    dropout=0.1,\n",
    "    rank=8,\n",
    "    adapter_scale=1.0,\n",
    "    train_eps=True,\n",
    ")\n",
    "dec_lora = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "save_path_lora = f\"checkpoints/lora_rel/{dataset}/best_rginlora_distmult_d={emb_dim}_L={num_layers}_mlp={hidden_layers}_rank={lora_rank}.pt\"\n",
    "\n",
    "res_lora = train_linkpred_typed(\n",
    "    enc_lora, dec_lora, dm_typed,\n",
    "    epochs=100,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=save_path_lora,   # your train loop already _safe_filename()s it\n",
    "    save_on_improve=True,\n",
    "    hparams={\n",
    "        \"dataset\": dataset,\n",
    "        \"decoder\": \"DistMult\",\n",
    "        \"emb_dim\": emb_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"hidden_layers\": hidden_layers,\n",
    "        \"rank\": lora_rank,\n",
    "        \"adapter_scale\": adapter_scale,\n",
    "        \"method\": \"LoRA-GIN\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Optional: print a standalone training report\n",
    "print_training_report(\n",
    "    model_name=\"LoRA R-GIN + DistMult\",\n",
    "    result=res_lora,\n",
    "    header_title=\"Model Training Results (LoRA)\",\n",
    "    save_path=f\"results/lora_rel/{dataset}/lora_rgin_distmult_d={emb_dim}_L={num_layers}_mlp={hidden_layers}_rank={lora_rank}.txt\"\n",
    ")"
   ],
   "id": "10ef1940bbb153fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: 40943 | Relations: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epochs (typed):   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "664e51c814bf45faa8b45e3d3c640329"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Train 1:   0%|          | 0/170 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2324aee58014460ac44258b3e1b7c2b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3ad6f87dc5151417"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
