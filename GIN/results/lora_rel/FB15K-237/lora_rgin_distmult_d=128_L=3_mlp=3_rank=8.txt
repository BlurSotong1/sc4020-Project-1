Model Training Results (LoRA) - 2025-10-18 18:59:30
================================================================================


LoRA R-GIN + DistMult Training History
============================================================

Best Validation AUC: 0.9812
Total Epochs Trained: 42
Early Stopping Best Score: 0.9259 (Hits@10 at epoch 32)

------------------------------------------------------------------------------------------
Epoch    Train Loss     Val AUC      Val H@1      Val H@5      Val H@10    
------------------------------------------------------------------------------------------
1        0.3539         0.9637       0.4222       0.7263       0.8506      
2        0.1962         0.9697       0.4548       0.7646       0.8806      
3        0.1733         0.9734       0.4723       0.7826       0.8929      
4        0.1599         0.9748       0.4887       0.7892       0.8968      
5        0.1529         0.9767       0.5066       0.8040       0.9046      
6        0.1488         0.9753       0.5076       0.8059       0.9087      
7        0.1454         0.9758       0.5097       0.8105       0.9075      
8        0.1420         0.9767       0.5096       0.8103       0.9107      
9        0.1390         0.9785       0.5233       0.8157       0.9128      
10       0.1363         0.9767       0.5265       0.8172       0.9150      
11       0.1347         0.9780       0.5234       0.8190       0.9161      
12       0.1342         0.9778       0.5198       0.8214       0.9151      
13       0.1326         0.9782       0.5221       0.8215       0.9168      
14       0.1318         0.9789       0.5261       0.8236       0.9176      
15       0.1304         0.9800       0.5225       0.8270       0.9182      
16       0.1294         0.9791       0.5366       0.8272       0.9190      
17       0.1290         0.9784       0.5354       0.8286       0.9188      
18       0.1272         0.9799       0.5403       0.8282       0.9193      
19       0.1270         0.9794       0.5318       0.8293       0.9185      
20       0.1269         0.9761       0.5177       0.8134       0.9070      
21       0.1258         0.9795       0.5348       0.8320       0.9186      
22       0.1240         0.9799       0.5393       0.8313       0.9194      
23       0.1239         0.9790       0.5397       0.8293       0.9218      
24       0.1236         0.9804       0.5416       0.8343       0.9214      
25       0.1227         0.9793       0.5470       0.8329       0.9222      
26       0.1221         0.9787       0.5408       0.8339       0.9221      
27       0.1211         0.9792       0.5453       0.8323       0.9206      
28       0.1221         0.9805       0.5392       0.8350       0.9232      
29       0.1206         0.9787       0.5378       0.8322       0.9218      
30       0.1210         0.9786       0.5518       0.8362       0.9215      
31       0.1199         0.9780       0.5427       0.8364       0.9224      
32       0.1214         0.9796       0.5429       0.8362       0.9259      
33       0.1195         0.9792       0.5480       0.8374       0.9249      
34       0.1188         0.9812       0.5429       0.8397       0.9236      
35       0.1181         0.9787       0.5478       0.8330       0.9227      
36       0.1185         0.9788       0.5450       0.8364       0.9226      
37       0.1180         0.9782       0.5410       0.8350       0.9239      
38       0.1191         0.9793       0.5469       0.8373       0.9232      
39       0.1184         0.9800       0.5440       0.8368       0.9229      
40       0.1178         0.9804       0.5535       0.8409       0.9237      
41       0.1177         0.9806       0.5594       0.8391       0.9258      
42       0.1168         0.9790       0.5498       0.8373       0.9240      
