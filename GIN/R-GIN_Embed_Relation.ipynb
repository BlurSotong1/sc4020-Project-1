{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T06:48:29.582755Z",
     "start_time": "2025-10-17T06:48:27.222567Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional, Dict, Any\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    _HAS_SK = True\n",
    "except Exception:\n",
    "    _HAS_SK = False\n",
    "\n",
    "\n",
    "class RelationalGINConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Relation-aware GIN:\n",
    "      m_{j→i} = (x_j ⊙ r_{e_{ij}})\n",
    "      x_i'    = MLP( (1+eps) * x_i + Σ_j m_{j→i} )\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim: int, num_relations: int, hidden_layers: int = 2, train_eps: bool = True):\n",
    "        super().__init__(aggr=\"add\")  # GIN uses sum\n",
    "        self.eps = nn.Parameter(torch.zeros(1)) if train_eps else nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "\n",
    "        # relation embeddings (one vector per relation id)\n",
    "        self.rel_emb = nn.Embedding(num_relations, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.rel_emb.weight)\n",
    "\n",
    "        # GIN MLP\n",
    "        layers = [nn.Linear(emb_dim, emb_dim * 2), nn.ReLU()]\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers += [nn.Linear(emb_dim * 2, emb_dim * 2), nn.ReLU()]\n",
    "        layers += [nn.Linear(emb_dim * 2, emb_dim)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_type: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: [N, d]\n",
    "        edge_index: [2, E]\n",
    "        edge_type: [E]  (relation id per edge)\n",
    "        \"\"\"\n",
    "        # Pass x through propagate so update(...) can receive it\n",
    "        return self.propagate(edge_index, x=x, edge_type=edge_type)\n",
    "\n",
    "    def message(self, x_j: torch.Tensor, edge_type: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x_j: [E, d] features of neighbors\n",
    "        edge_type: [E] relation ids aligned with edges\n",
    "        \"\"\"\n",
    "        r = self.rel_emb(edge_type)        # [E, d]\n",
    "        return x_j * r                     # elementwise modulation by relation\n",
    "\n",
    "    def update(self, aggr_out: torch.Tensor, x: torch.Tensor = None, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        aggr_out: [N, d] summed messages\n",
    "        x: original node features [N, d] (passed via propagate kwargs)\n",
    "        \"\"\"\n",
    "        out = (1.0 + self.eps) * x + aggr_out\n",
    "        return self.mlp(out)\n",
    "\n",
    "\n",
    "class RelationalGINEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes: int, num_relations: int,\n",
    "                 emb_dim: int = 128, num_layers: int = 3,\n",
    "                 hidden_layers: int = 2, dropout: float = 0.1, train_eps: bool = True):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(num_nodes, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.embed.weight)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            RelationalGINConv(emb_dim, num_relations, hidden_layers=hidden_layers, train_eps=train_eps)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, edge_index: torch.Tensor, edge_type: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embed.weight\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_type)\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d629dc198a6c4f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T06:48:29.600125Z",
     "start_time": "2025-10-17T06:48:29.587465Z"
    }
   },
   "source": [
    "def _fmt_ts(dt: datetime) -> str:\n",
    "    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def _fmt(x):\n",
    "    try:\n",
    "        return f\"{float(x):.4f}\"\n",
    "    except Exception:\n",
    "        return \"nan\"\n",
    "\n",
    "def print_comparison_report(\n",
    "        title: str,\n",
    "        left_name: str, left_result: Dict[str, Any],\n",
    "        right_name: str, right_result: Dict[str, Any],\n",
    "        save_path: Optional[str | Path] = None,\n",
    "):\n",
    "    ts = _fmt_ts(datetime.now())\n",
    "\n",
    "    def block(name, res):\n",
    "        best = res[\"best\"]; hist = res[\"history\"]\n",
    "        best_auc = max((h.get(\"val_auc\", float(\"nan\")) for h in hist), default=float(\"nan\"))\n",
    "        total_epochs = res.get(\"epochs_trained\", len(hist))\n",
    "\n",
    "        lines = []\n",
    "        lines.append(f\"{name} Training History\")\n",
    "        lines.append(\"=\" * 60)\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"Best Validation AUC: {_fmt(best_auc)}\")\n",
    "        lines.append(f\"Total Epochs Trained: {total_epochs}\")\n",
    "        lines.append(f\"Early Stopping Best Score: {_fmt(best.get('Hits@10'))} (Hits@10 at epoch {best.get('epoch')})\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"-\" * 90)\n",
    "        lines.append(f\"{'Epoch':<8} {'Train Loss':<14} {'Val AUC':<12} {'Val H@1':<12} {'Val H@5':<12} {'Val H@10':<12}\")\n",
    "        lines.append(\"-\" * 90)\n",
    "        for rec in hist:\n",
    "            e = rec.get(\"epoch\")\n",
    "            lines.append(\n",
    "                f\"{e:<8} \"\n",
    "                f\"{_fmt(rec.get('train_loss')):<14} \"\n",
    "                f\"{_fmt(rec.get('val_auc')):<12} \"\n",
    "                f\"{_fmt(rec.get('val_hits1')):<12} \"\n",
    "                f\"{_fmt(rec.get('val_hits5')):<12} \"\n",
    "                f\"{_fmt(rec.get('val_hits10')):<12}\"\n",
    "            )\n",
    "        lines.append(\"\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    out = []\n",
    "    out.append(f\"{title} - {ts}\")\n",
    "    out.append(\"=\" * 80)\n",
    "    out.append(\"\")\n",
    "    out.append(block(left_name, left_result))\n",
    "    out.append(block(right_name, right_result))\n",
    "\n",
    "    # Best-at-a-glance\n",
    "    out.append(\"Best Validation Metrics Summary\")\n",
    "    out.append(\"=\" * 60)\n",
    "    for name, res in [(left_name, left_result), (right_name, right_result)]:\n",
    "        b = res[\"best\"]\n",
    "        out.append(\n",
    "            f\"{name}: \"\n",
    "            f\"AUC={_fmt(b.get('AUC'))} | \"\n",
    "            f\"H@1={_fmt(b.get('Hits@1'))} | \"\n",
    "            f\"H@5={_fmt(b.get('Hits@5'))} | \"\n",
    "            f\"H@10={_fmt(b.get('Hits@10'))} \"\n",
    "            f\"(epoch {b.get('epoch')})\"\n",
    "        )\n",
    "    out.append(\"\")\n",
    "\n",
    "    report = \"\\n\".join(out)\n",
    "    print(report)\n",
    "\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\n✅ Comparison report saved to: {save_path.resolve()}\")\n",
    "\n",
    "\n",
    "def print_training_report(\n",
    "        model_name: str,\n",
    "        result: Dict[str, Any],\n",
    "        header_title: str = \"Model Training Results\",\n",
    "        save_path: Optional[str | Path] = None,\n",
    "):\n",
    "    ts = _fmt_ts(result.get(\"end_time\", datetime.now()))\n",
    "    best = result[\"best\"]\n",
    "    history = result[\"history\"]\n",
    "    total_epochs = result.get(\"epochs_trained\", len(history))\n",
    "    best_auc = max((h.get(\"val_auc\", float(\"nan\")) for h in history), default=float(\"nan\"))\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"{header_title} - {ts}\")\n",
    "    lines.append(\"=\" * 80)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"{model_name} Training History\")\n",
    "    lines.append(\"=\" * 60)\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"Best Validation AUC: {_fmt(best_auc)}\")\n",
    "    lines.append(f\"Total Epochs Trained: {total_epochs}\")\n",
    "    lines.append(f\"Early Stopping Best Score: {_fmt(best.get('Hits@10'))} (Hits@10 at epoch {best.get('epoch')})\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"-\" * 90)\n",
    "    lines.append(f\"{'Epoch':<8} {'Train Loss':<14} {'Val AUC':<12} {'Val H@1':<12} {'Val H@5':<12} {'Val H@10':<12}\")\n",
    "    lines.append(\"-\" * 90)\n",
    "\n",
    "    for rec in history:\n",
    "        e = rec.get(\"epoch\")\n",
    "        lines.append(\n",
    "            f\"{e:<8} \"\n",
    "            f\"{_fmt(rec.get('train_loss')):<14} \"\n",
    "            f\"{_fmt(rec.get('val_auc')):<12} \"\n",
    "            f\"{_fmt(rec.get('val_hits1')):<12} \"\n",
    "            f\"{_fmt(rec.get('val_hits5')):<12} \"\n",
    "            f\"{_fmt(rec.get('val_hits10')):<12}\"\n",
    "        )\n",
    "\n",
    "    lines.append(\"\")\n",
    "    report_text = \"\\n\".join(lines)\n",
    "\n",
    "    print(report_text)\n",
    "\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report_text)\n",
    "        print(f\"\\n✅ Report saved to: {save_path.resolve()}\")\n",
    "\n",
    "\n",
    "# ---------- Build edge_index and edge_type from the *train* split ----------\n",
    "def build_edge_index_and_type_from_typed_dm(dm) -> tuple[torch.LongTensor, torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        edge_index: [2, E] directed edges\n",
    "        edge_type:  [E]    relation id per edge (aligned with edge_index columns)\n",
    "    Uses dm._train_triples directly (already contains reverse triples if add_reverse=True).\n",
    "    \"\"\"\n",
    "    assert hasattr(dm, \"_train_triples\"), \"KGDataModuleTyped expected.\"\n",
    "    triples = dm._train_triples  # [N, 3] (h, r, t), torch.long\n",
    "    if triples.numel() == 0:\n",
    "        return torch.empty(2, 0, dtype=torch.long), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    h = triples[:, 0]\n",
    "    r = triples[:, 1]\n",
    "    t = triples[:, 2]\n",
    "\n",
    "    edge_index = torch.stack([h, t], dim=0).contiguous()  # directed edges h->t\n",
    "    edge_type = r.contiguous()                             # relation per edge\n",
    "    return edge_index, edge_type\n",
    "\n",
    "\n",
    "# ---------- Typed negative sampling (corrupt head/tail, keep relation) ----------\n",
    "@torch.no_grad()\n",
    "def sample_negatives_typed(triples: torch.Tensor, num_entities: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    1:1 negatives per positive (half head-corrupt, half tail-corrupt).\n",
    "    Input triples: [B,3] (h, r, t)\n",
    "    Output triples: [B,3] negatives (h', r, t) or (h, r, t')\n",
    "    \"\"\"\n",
    "    B = triples.size(0)\n",
    "    device = triples.device\n",
    "    neg = triples.clone()\n",
    "    flip = torch.rand(B, device=device) < 0.5\n",
    "    rand_ents = torch.randint(0, num_entities, (B,), device=device)\n",
    "\n",
    "    # corrupt head\n",
    "    neg[flip, 0] = rand_ents[flip]\n",
    "    # corrupt tail\n",
    "    neg[~flip, 2] = rand_ents[~flip]\n",
    "    return neg\n",
    "\n",
    "\n",
    "# ---------- DistMult decoder for typed link prediction ----------\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    score(h, r, t) = <e_h, w_r, e_t> = sum_d e_h[d] * w_r[d] * e_t[d]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_relations: int, dim: int):\n",
    "        super().__init__()\n",
    "        self.rel = torch.nn.Embedding(num_relations, dim)\n",
    "        torch.nn.init.xavier_uniform_(self.rel.weight)\n",
    "\n",
    "    def forward(self, z: torch.Tensor, triples: torch.LongTensor) -> torch.Tensor:\n",
    "        # triples: [B,3] (h, r, t)\n",
    "        h, r, t = triples[:, 0], triples[:, 1], triples[:, 2]\n",
    "        e_h, e_t, w_r = z[h], z[t], self.rel(r)\n",
    "        return (e_h * w_r * e_t).sum(dim=1)  # [B]\n",
    "\n",
    "class DotProductDecoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    score(h, r, t) = <e_h, e_t> (relation is ignored)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z: torch.Tensor, triples: torch.LongTensor) -> torch.Tensor:\n",
    "        h, t = triples[:, 0], triples[:, 2]\n",
    "        return (z[h] * z[t]).sum(dim=1)  # [B]\n",
    "\n",
    "def scores_for_candidates(\n",
    "        decoder: torch.nn.Module,\n",
    "        z: torch.Tensor,\n",
    "        h: torch.Tensor,                # [B]\n",
    "        r: torch.Tensor,                # [B]\n",
    "        cand_t: torch.Tensor,           # [B, K]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns [B, K] scores for candidates.\n",
    "    Fast path for DistMult; generic path for DotProduct.\n",
    "    \"\"\"\n",
    "    if isinstance(decoder, DistMultDecoder):\n",
    "        e_h = z[h]                       # [B, d]\n",
    "        w_r = decoder.rel(r)            # [B, d]\n",
    "        e_c = z[cand_t]                 # [B, K, d]\n",
    "        s = ((e_h * w_r).unsqueeze(1) * e_c).sum(dim=2)  # [B, K]\n",
    "        return s\n",
    "    else:\n",
    "        # generic: build triples and call decoder\n",
    "        B, K = cand_t.shape\n",
    "        h_rep = h.view(B, 1).expand(B, K)\n",
    "        r_rep = r.view(B, 1).expand(B, K)  # unused by dot, but fine for API\n",
    "        triples = torch.stack([h_rep, r_rep, cand_t], dim=2).reshape(-1, 3)  # [B*K,3]\n",
    "        s = decoder(z, triples).view(B, K)\n",
    "        return s"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "69cbef8c22eec1b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T06:48:29.609127Z",
     "start_time": "2025-10-17T06:48:29.603784Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_metrics_typed(\n",
    "        encoder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,\n",
    "        edge_index: torch.Tensor,\n",
    "        edge_type: torch.Tensor,\n",
    "        loader: Optional[DataLoader],\n",
    "        num_entities: int,\n",
    "        device: torch.device,\n",
    "        show_tqdm: bool = False,\n",
    ") -> Dict[str, float]:\n",
    "    if loader is None:\n",
    "        return {\"AUC\": float(\"nan\"), \"Hits@1\": float(\"nan\"), \"Hits@5\": float(\"nan\"), \"Hits@10\": float(\"nan\")}\n",
    "\n",
    "    encoder.eval(); decoder.eval()\n",
    "    z = encoder(edge_index.to(device), edge_type.to(device))  # [N, d]\n",
    "\n",
    "    # --- AUC ---\n",
    "    all_scores, all_labels = [], []\n",
    "    it_auc = loader if not show_tqdm else tqdm(loader, leave=False, desc=\"Eval AUC (typed)\")\n",
    "    for pos, _ in it_auc:\n",
    "        pos = pos.to(device)\n",
    "        neg = sample_negatives_typed(pos, num_entities)\n",
    "\n",
    "        s_pos = decoder(z, pos)\n",
    "        s_neg = decoder(z, neg)\n",
    "\n",
    "        all_scores.append(torch.cat([s_pos, s_neg]).detach().cpu().numpy())\n",
    "        all_labels.append(np.concatenate([np.ones(len(s_pos)), np.zeros(len(s_neg))]))\n",
    "\n",
    "    scores = np.concatenate(all_scores) if len(all_scores) > 0 else np.array([])\n",
    "    labels = np.concatenate(all_labels) if len(all_labels) > 0 else np.array([])\n",
    "    if _HAS_SK and len(scores) > 0:\n",
    "        auc = float(roc_auc_score(labels, scores))\n",
    "    else:\n",
    "        auc = float(\"nan\") if len(scores) == 0 else float((scores[labels == 1].mean() > scores[labels == 0].mean()))\n",
    "\n",
    "    # --- Hits@K (tail ranking) ---\n",
    "    hits1 = hits5 = hits10 = 0\n",
    "    trials = 0\n",
    "    it_hits = loader if not show_tqdm else tqdm(loader, leave=False, desc=\"Eval Hits (tail)\")\n",
    "    for pos, _ in it_hits:\n",
    "        pos = pos.to(device)\n",
    "        B = pos.size(0)\n",
    "        h, r, t_true = pos[:, 0], pos[:, 1], pos[:, 2]\n",
    "\n",
    "        rand_t = torch.randint(0, num_entities, (B, 99), device=device)\n",
    "        cand_t = torch.cat([t_true.view(-1, 1), rand_t], dim=1)  # [B,100]\n",
    "\n",
    "        s = scores_for_candidates(decoder, z, h, r, cand_t)  # [B,100]\n",
    "        ranks = s.argsort(dim=1, descending=True)\n",
    "        true_positions = torch.nonzero(ranks == 0, as_tuple=False)[:, 1] + 1  # 1-based\n",
    "        hits1  += (true_positions <= 1).sum().item()\n",
    "        hits5  += (true_positions <= 5).sum().item()\n",
    "        hits10 += (true_positions <= 10).sum().item()\n",
    "        trials += B\n",
    "\n",
    "    return {\n",
    "        \"AUC\": auc,\n",
    "        \"Hits@1\": hits1 / max(trials, 1),\n",
    "        \"Hits@5\": hits5 / max(trials, 1),\n",
    "        \"Hits@10\": hits10 / max(trials, 1),\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "41621913c69ec50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T06:48:29.621272Z",
     "start_time": "2025-10-17T06:48:29.612513Z"
    }
   },
   "source": [
    "def train_linkpred_typed(\n",
    "        encoder: torch.nn.Module,\n",
    "        decoder: torch.nn.Module,                 # DistMultDecoder (or another typed decoder)\n",
    "        dm,                                       # KGDataModuleTyped\n",
    "        epochs: int = 100,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 1e-4,\n",
    "        patience: int = 10,\n",
    "        device: Optional[torch.device] = None,\n",
    "        show_tqdm: bool = True,\n",
    "        save_best_path: Optional[str | Path] = None,\n",
    "        save_on_improve: bool = True,\n",
    "        hparams: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    # Optimizer only over encoder + decoder\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Build typed graph from *train* split\n",
    "    edge_index, edge_type = build_edge_index_and_type_from_typed_dm(dm)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_type  = edge_type.to(device)\n",
    "\n",
    "    train_loader = dm.train_loader()\n",
    "    val_loader   = dm.val_loader()\n",
    "    num_entities = len(dm.ent2id)\n",
    "    num_relations = len(dm.rel2id)\n",
    "\n",
    "    # hparams\n",
    "    auto_hparams: Dict[str, Any] = {\n",
    "        \"model_name\": f\"{encoder.__class__.__name__}+{decoder.__class__.__name__}\",\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"patience\": patience,\n",
    "        \"typed_graph\": True,\n",
    "        \"batch_size\": getattr(dm, \"batch_size\", None),\n",
    "        \"add_reverse\": getattr(dm, \"add_reverse\", None),\n",
    "        \"reverse_relation_strategy\": getattr(dm, \"reverse_relation_strategy\", None),\n",
    "        \"num_nodes\": len(dm.ent2id),\n",
    "        \"num_relations\": num_relations,\n",
    "        \"enc_emb_dim\": getattr(getattr(encoder, \"embed\", None), \"embedding_dim\", None),\n",
    "        \"enc_num_layers\": len(getattr(encoder, \"convs\", [])),\n",
    "        \"decoder\": decoder.__class__.__name__,\n",
    "    }\n",
    "    run_hparams = {**auto_hparams, **(hparams or {})}\n",
    "\n",
    "    history = []\n",
    "    best = {\"epoch\": 0, \"AUC\": -1.0, \"Hits@1\": 0.0, \"Hits@5\": 0.0, \"Hits@10\": 0.0}\n",
    "    patience_ctr = 0\n",
    "    best_state = None\n",
    "\n",
    "    save_best_path = Path(save_best_path) if save_best_path else None\n",
    "    if save_best_path:\n",
    "        save_best_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    epoch_iter = range(1, epochs + 1)\n",
    "    if show_tqdm:\n",
    "        epoch_iter = tqdm(epoch_iter, desc=\"Epochs (typed)\")\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        encoder.train(); decoder.train()\n",
    "        running_loss = 0.0\n",
    "        running_n = 0\n",
    "\n",
    "        batch_iter = train_loader\n",
    "        if show_tqdm:\n",
    "            batch_iter = tqdm(train_loader, leave=False, desc=f\"Train {epoch}\")\n",
    "\n",
    "        # Precompute node embeddings once per epoch for efficiency\n",
    "        z = encoder(edge_index, edge_type)  # [N, d]\n",
    "\n",
    "        for pos, _ in batch_iter:\n",
    "            pos = pos.to(device)\n",
    "            neg = sample_negatives_typed(pos, num_entities).to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # recompute embeddings for THIS batch so we have a fresh graph\n",
    "            z = encoder(edge_index, edge_type)              # <— moved inside\n",
    "\n",
    "            s_pos = decoder(z, pos)\n",
    "            s_neg = decoder(z, neg)\n",
    "\n",
    "            scores = torch.cat([s_pos, s_neg], dim=0)\n",
    "            labels = torch.cat([torch.ones_like(s_pos), torch.zeros_like(s_neg)], dim=0)\n",
    "            loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_n += 1\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(encoder.parameters()) + list(decoder.parameters()), max_norm=1.0\n",
    "            )\n",
    "            opt.step()\n",
    "\n",
    "            if show_tqdm:\n",
    "                batch_iter.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        train_loss = running_loss / max(running_n, 1)\n",
    "\n",
    "        # Validation (fresh z to reflect updated encoder)\n",
    "        val_metrics = evaluate_metrics_typed(\n",
    "            encoder, decoder, edge_index, edge_type, val_loader, num_entities, device, show_tqdm=show_tqdm\n",
    "        )\n",
    "        if show_tqdm:\n",
    "            tqdm.write(f\"Epoch {epoch:03d} | loss={train_loss:.4f} | \"\n",
    "                       f\"AUC={val_metrics['AUC']:.4f} | \"\n",
    "                       f\"H@1={val_metrics['Hits@1']:.4f} | \"\n",
    "                       f\"H@5={val_metrics['Hits@5']:.4f} | \"\n",
    "                       f\"H@10={val_metrics['Hits@10']:.4f}\")\n",
    "\n",
    "        history.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"val_auc\": float(val_metrics[\"AUC\"]),\n",
    "            \"val_hits1\": float(val_metrics[\"Hits@1\"]),\n",
    "            \"val_hits5\": float(val_metrics[\"Hits@5\"]),\n",
    "            \"val_hits10\": float(val_metrics[\"Hits@10\"]),\n",
    "        })\n",
    "\n",
    "        # Early stopping on Hits@10\n",
    "        if val_metrics[\"Hits@10\"] > best[\"Hits@10\"]:\n",
    "            best.update({\"epoch\": epoch, **val_metrics})\n",
    "            best_state = {\n",
    "                \"encoder\": {k: v.detach().cpu() for k, v in encoder.state_dict().items()},\n",
    "                \"decoder\": {k: v.detach().cpu() for k, v in decoder.state_dict().items()},\n",
    "            }\n",
    "            patience_ctr = 0\n",
    "\n",
    "            if save_best_path and save_on_improve:\n",
    "                torch.save({\n",
    "                    \"encoder_state_dict\": best_state[\"encoder\"],\n",
    "                    \"decoder_state_dict\": best_state[\"decoder\"],\n",
    "                    \"epoch\": epoch,\n",
    "                    \"best_metrics\": best,\n",
    "                    \"history\": history,\n",
    "                    \"hparams\": run_hparams,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                },\n",
    "                    save_best_path,\n",
    "                )\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                if show_tqdm:\n",
    "                    tqdm.write(f\"Early stopping at epoch {epoch} (patience={patience}).\")\n",
    "                break\n",
    "\n",
    "    # Restore best\n",
    "    end_time = datetime.now()\n",
    "    if best_state is not None:\n",
    "        encoder.load_state_dict(best_state[\"encoder\"])\n",
    "        decoder.load_state_dict(best_state[\"decoder\"])\n",
    "        if show_tqdm:\n",
    "            tqdm.write(f\"Restored best model from epoch {best['epoch']} | \"\n",
    "                       f\"AUC={best['AUC']:.4f} | Hits@10={best['Hits@10']:.4f}\")\n",
    "\n",
    "        # If you prefer single save at end:\n",
    "        if save_best_path and not save_on_improve:\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"encoder_state_dict\": best_state[\"encoder\"],\n",
    "                    \"decoder_state_dict\": best_state[\"decoder\"],\n",
    "                    \"epoch\": best[\"epoch\"],\n",
    "                    \"best_metrics\": best,\n",
    "                    \"history\": history,\n",
    "                    \"hparams\": run_hparams,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                },\n",
    "                save_best_path,\n",
    "            )\n",
    "            if show_tqdm:\n",
    "                tqdm.write(f\"Saved final best checkpoint to {save_best_path}\")\n",
    "\n",
    "    return {\n",
    "        \"best\": best,\n",
    "        \"history\": history,\n",
    "        \"epochs_trained\": history[-1][\"epoch\"] if history else 0,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "        \"checkpoint_path\": str(save_best_path) if save_best_path else None,\n",
    "        \"hparams\": run_hparams,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d93c079a56a0fbf8",
   "metadata": {},
   "source": [
    "from dataset_loader import KGDataModuleTyped\n",
    "\n",
    "dataset = \"WN18RR\"\n",
    "train_p = Path(\"../WN18RR/train.txt\")\n",
    "valid_p = Path(\"../WN18RR/valid.txt\")\n",
    "test_p  = Path(\"../WN18RR/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 3\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "# --- 2) R-GIN + DotProduct ---\n",
    "enc_dot = RelationalGINEncoder(\n",
    "    num_nodes=num_nodes,\n",
    "    num_relations=num_relations,\n",
    "    emb_dim=emb_dim,\n",
    "    num_layers=num_layers,\n",
    "    hidden_layers=hidden_layers,\n",
    "    dropout=0.1,\n",
    "    train_eps=True,\n",
    ")\n",
    "dec_dot = DotProductDecoder()\n",
    "\n",
    "res_dot = train_linkpred_typed(\n",
    "    enc_dot, dec_dot, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_dot|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DotProduct\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "# --- 3) Single combined report ---\n",
    "print_comparison_report(\n",
    "    title=\"Typed Link Prediction: Decoder Comparison\",\n",
    "    left_name=\"R-GIN + DistMult\",\n",
    "    left_result=res_distmult,\n",
    "    right_name=\"R-GIN + DotProduct\",\n",
    "    right_result=res_dot,\n",
    "    save_path=f\"results/embed_rel/{dataset}/comparison_rgin_distmult_vs_dot|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11d01bec-80a0-4236-839a-a0c27a17634c",
   "metadata": {},
   "source": [
    "dataset = \"WN18RR\"\n",
    "train_p = Path(\"../WN18RR/train.txt\")\n",
    "valid_p = Path(\"../WN18RR/valid.txt\")\n",
    "test_p  = Path(\"../WN18RR/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 2\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "\n",
    "print_training_report(\n",
    "        model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "        result = res_distmult,\n",
    "        header_title = \"Model Training Results\",\n",
    "        save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = \"WN18RR\"\n",
    "train_p = Path(\"../WN18RR/train.txt\")\n",
    "valid_p = Path(\"../WN18RR/valid.txt\")\n",
    "test_p  = Path(\"../WN18RR/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 4\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "\n",
    "print_training_report(\n",
    "    model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "    result = res_distmult,\n",
    "    header_title = \"Model Training Results\",\n",
    "    save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "id": "2b5ab0372f7aa7aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = \"WN18RR\"\n",
    "train_p = Path(\"../WN18RR/train.txt\")\n",
    "valid_p = Path(\"../WN18RR/valid.txt\")\n",
    "test_p  = Path(\"../WN18RR/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 4\n",
    "hidden_layers = 4\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "\n",
    "print_training_report(\n",
    "    model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "    result = res_distmult,\n",
    "    header_title = \"Model Training Results\",\n",
    "    save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "id": "e4efdec5649d3ce3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = \"WN18RR\"\n",
    "train_p = Path(\"../WN18RR/train.txt\")\n",
    "valid_p = Path(\"../WN18RR/valid.txt\")\n",
    "test_p  = Path(\"../WN18RR/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 4\n",
    "hidden_layers = 2\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "\n",
    "print_training_report(\n",
    "    model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "    result = res_distmult,\n",
    "    header_title = \"Model Training Results\",\n",
    "    save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "id": "9ca44ac52bb4ebe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d912b339cb439010",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FB15k-237 training",
   "id": "846dbb3fd1c8539d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-17T06:42:50.680218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_loader import KGDataModuleTyped\n",
    "\n",
    "dataset = \"FB15K-237\"\n",
    "train_p = Path(\"../FB15K-237/train.txt\")\n",
    "valid_p = Path(\"../FB15K-237/valid.txt\")\n",
    "test_p  = Path(\"../FB15K-237/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 3\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "# --- 2) R-GIN + DotProduct ---\n",
    "enc_dot = RelationalGINEncoder(\n",
    "    num_nodes=num_nodes,\n",
    "    num_relations=num_relations,\n",
    "    emb_dim=emb_dim,\n",
    "    num_layers=num_layers,\n",
    "    hidden_layers=hidden_layers,\n",
    "    dropout=0.1,\n",
    "    train_eps=True,\n",
    ")\n",
    "dec_dot = DotProductDecoder()\n",
    "\n",
    "res_dot = train_linkpred_typed(\n",
    "    enc_dot, dec_dot, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_dot|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DotProduct\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "# --- 3) Single combined report ---\n",
    "print_comparison_report(\n",
    "    title=\"Typed Link Prediction: Decoder Comparison\",\n",
    "    left_name=\"R-GIN + DistMult\",\n",
    "    left_result=res_distmult,\n",
    "    right_name=\"R-GIN + DotProduct\",\n",
    "    right_result=res_dot,\n",
    "    save_path=f\"results/embed_rel/{dataset}/comparison_rgin_distmult_vs_dot|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 2\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "print_training_report(\n",
    "    model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "    result = res_distmult,\n",
    "    header_title = \"Model Training Results\",\n",
    "    save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "id": "7b84f90490b8f7e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epochs (typed):   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c1834faccde4adb8928f6c33da3ffa6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Train 1:   0%|          | 0/266 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b9ee462033d44ed9cb3073d2473f118"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-17T06:48:37.363291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_loader import KGDataModuleTyped\n",
    "\n",
    "dataset = \"FB15K-237\"\n",
    "train_p = Path(\"../FB15K-237/train.txt\")\n",
    "valid_p = Path(\"../FB15K-237/valid.txt\")\n",
    "test_p  = Path(\"../FB15K-237/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 4\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "print_training_report(\n",
    "    model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "    result = res_distmult,\n",
    "    header_title = \"Model Training Results\",\n",
    "    save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=True,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 4\n",
    "hidden_layers = 4\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")\n",
    "\n",
    "\n",
    "print_training_report(\n",
    "    model_name = \"R-GIN_embed_rel + Distmult\",\n",
    "    result = res_distmult,\n",
    "    header_title = \"Model Training Results\",\n",
    "    save_path=f\"results/embed_rel/{dataset}/embed_rel_gin_report|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.txt\"\n",
    ")"
   ],
   "id": "4011077d5d5c8e89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epochs (typed):   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc1fcf632ce841d7b83dc24aea97962d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Train 1:   0%|          | 0/266 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8196c46ec4ef40f7b35d3e6e7859df2d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T06:45:44.666190Z",
     "start_time": "2025-10-17T06:41:26.049602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cora_to_kg.py\n",
    "# Convert Cora (PyG) into WN18RR-style TSV triples your loader can read.\n",
    "\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import coalesce\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# ------------------------- config -------------------------\n",
    "root = Path(\"./data\")\n",
    "out_dir = root / \"CORA_KG\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "relation_name = \"cites\"            # single relation\n",
    "is_undirected_split = True         # safer split for citation graphs\n",
    "add_reverse_edges = True           # also write reverse edges\n",
    "reverse_relation_strategy = \"duplicate_rel\"  # or \"same_rel\"\n",
    "\n",
    "# --------------------- load + coalesce --------------------\n",
    "print(\"📥 Loading Cora via PyG (auto-download if needed)...\")\n",
    "dataset = Planetoid(root=str(root), name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "# coalesce deduplicates edges; keep them as-is (directed list)\n",
    "edge_index, _ = coalesce(data.edge_index, None, data.num_nodes, data.num_nodes)\n",
    "\n",
    "# Build a Data object with the coalesced edges (older PyG has no .replace)\n",
    "new_data = Data(\n",
    "    x=data.x,\n",
    "    y=data.y,\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    ")\n",
    "\n",
    "print(f\"✅ Cora: num_nodes={data.num_nodes}, edges={edge_index.size(1)}\")\n",
    "\n",
    "# ------------------- train/val/test split -----------------\n",
    "splitter = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=is_undirected_split,\n",
    "    add_negative_train_samples=False,  # you sample negatives yourself\n",
    ")\n",
    "train_g, val_g, test_g = splitter(new_data)\n",
    "\n",
    "def pos_edges(g: Data) -> torch.Tensor:\n",
    "    # RandomLinkSplit attaches edge_label and edge_label_index\n",
    "    mask = (g.edge_label == 1)\n",
    "    return g.edge_label_index[:, mask]  # [2, E_pos]\n",
    "\n",
    "train_edges = pos_edges(train_g)\n",
    "val_edges   = pos_edges(val_g)\n",
    "test_edges  = pos_edges(test_g)\n",
    "\n",
    "print(f\"📊 Splits: train={train_edges.size(1)}, val={val_edges.size(1)}, test={test_edges.size(1)}\")\n",
    "\n",
    "# -------------------- triples + saving --------------------\n",
    "def make_triples(edge_idx: torch.Tensor,\n",
    "                 rel: str,\n",
    "                 add_rev: bool,\n",
    "                 rev_strategy: str) -> list[tuple[str, str, str]]:\n",
    "    triples = []\n",
    "    h_list = edge_idx[0].tolist()\n",
    "    t_list = edge_idx[1].tolist()\n",
    "    for h, t in zip(h_list, t_list):\n",
    "        triples.append((f\"n{h}\", rel, f\"n{t}\"))\n",
    "        if add_rev:\n",
    "            if rev_strategy == \"duplicate_rel\":\n",
    "                triples.append((f\"n{t}\", rel + \"_rev\", f\"n{h}\"))\n",
    "            else:  # same_rel\n",
    "                triples.append((f\"n{t}\", rel, f\"n{h}\"))\n",
    "    return triples\n",
    "\n",
    "def save_triples(triples: list[tuple[str, str, str]], path: Path) -> None:\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f, delimiter=\"\\t\")\n",
    "        writer.writerows(triples)\n",
    "    print(f\"💾 Saved {len(triples):,} triples -> {path}\")\n",
    "\n",
    "train_triples = make_triples(train_edges, relation_name, add_reverse_edges, reverse_relation_strategy)\n",
    "val_triples   = make_triples(val_edges,   relation_name, add_reverse_edges, reverse_relation_strategy)\n",
    "test_triples  = make_triples(test_edges,  relation_name, add_reverse_edges, reverse_relation_strategy)\n",
    "\n",
    "save_triples(train_triples, out_dir / \"train.txt\")\n",
    "save_triples(val_triples,   out_dir / \"valid.txt\")\n",
    "save_triples(test_triples,  out_dir / \"test.txt\")\n",
    "\n",
    "print(\"✅ Done. Files are WN18RR-style and compatible with your KGDataModuleTyped.\")\n",
    "print(f\"Use paths:\\n  train: {out_dir/'train.txt'}\\n  valid: {out_dir/'valid.txt'}\\n  test : {out_dir/'test.txt'}\")"
   ],
   "id": "c71cdec356ffa9c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading Cora via PyG (auto-download if needed)...\n",
      "✅ Cora: num_nodes=2708, edges=10556\n",
      "📊 Splits: train=4224, val=527, test=527\n",
      "💾 Saved 8,448 triples -> data/CORA_KG/train.txt\n",
      "💾 Saved 1,054 triples -> data/CORA_KG/valid.txt\n",
      "💾 Saved 1,054 triples -> data/CORA_KG/test.txt\n",
      "✅ Done. Files are WN18RR-style and compatible with your KGDataModuleTyped.\n",
      "Use paths:\n",
      "  train: data/CORA_KG/train.txt\n",
      "  valid: data/CORA_KG/valid.txt\n",
      "  test : data/CORA_KG/test.txt\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T06:40:15.522323Z",
     "start_time": "2025-10-17T06:39:12.517797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_loader import KGDataModuleTyped\n",
    "dataset = \"Cora\"\n",
    "train_p =  Path(\"data/CORA_KG/train.txt\")\n",
    "valid_p = Path(\"data/CORA_KG/valid.txt\")\n",
    "test_p = Path(\"data/CORA_KG/test.txt\")\n",
    "\n",
    "dm_typed = KGDataModuleTyped(\n",
    "    train_p, valid_p, test_p,\n",
    "    add_reverse=False,\n",
    "    reverse_relation_strategy=\"duplicate_rel\",\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "num_nodes = len(dm_typed.ent2id)\n",
    "num_relations = len(dm_typed.rel2id)\n",
    "emb_dim = 128\n",
    "num_layers = 2\n",
    "hidden_layers = 3\n",
    "\n",
    "# --- 1) R-GIN + DistMult ---\n",
    "enc_dm = RelationalGINEncoder( num_nodes=num_nodes, num_relations=num_relations, emb_dim=emb_dim, num_layers=num_layers, hidden_layers=hidden_layers, dropout=0.1, train_eps=True\n",
    "                               )\n",
    "dec_dm = DistMultDecoder(num_relations=num_relations, dim=emb_dim)\n",
    "\n",
    "\n",
    "\n",
    "res_distmult = train_linkpred_typed(\n",
    "    enc_dm, dec_dm, dm_typed,\n",
    "    epochs=100, lr=1e-3, weight_decay=1e-4, patience=10,\n",
    "    show_tqdm=True,\n",
    "    save_best_path=f\"checkpoints/embed_rel/{dataset}/best_rgin_distmult|embed_dim={emb_dim}|mlp_depth={hidden_layers}|aggre={num_layers}|dataset={dataset}.pt\",\n",
    "    save_on_improve=True,\n",
    "    hparams={\"dataset\": dataset, \"decoder\": \"DistMult\", \"emb_dim\": emb_dim, \"num_layers\": num_layers, \"hidden_layers\": hidden_layers}\n",
    ")"
   ],
   "id": "7b311c04a8fba1d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epochs (typed):   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "322377c8e25c4e03a1a5f2cf37277568"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Train 1:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73d4c035da844593976c8d72d81d248d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bef036454e54b5d846c6b659409c564"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a388536fb71464fa5b886b591d72680"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | loss=0.6713 | AUC=0.5315 | H@1=0.0607 | H@5=0.1765 | H@10=0.2438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 2:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "925e1119e99447c7a6ee35e11af762d7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b96b11c5a6734a449686c472a98d663d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bb5cf40248e41518b1b1681a8d862f9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | loss=0.6487 | AUC=0.5537 | H@1=0.0607 | H@5=0.1774 | H@10=0.2448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 3:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a706b764406145ea9560055b97ad3da6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12b5f7eed3ab4064af7a5e38eda776d3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a34bbee38c1450a8d1252247399df1f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | loss=0.6474 | AUC=0.5714 | H@1=0.0712 | H@5=0.1651 | H@10=0.2249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 4:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "485ce29b08394f5db559d8eb6d57a675"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e57f4c09f3445f488f00f6062b2c1f4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "769ba63ae438494a9629b37bf18bc739"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | loss=0.6481 | AUC=0.5590 | H@1=0.0778 | H@5=0.1860 | H@10=0.2638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 5:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04e1c52e0bca4ecca9b8e1ef880ae8e4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05716c93d73e4a53953ef8fa8f792dcf"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "866da21c4a324a4faa2a045f0e8287e6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | loss=0.6472 | AUC=0.5654 | H@1=0.0863 | H@5=0.1898 | H@10=0.2476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 6:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f3a5ad823b74cfc9407c223dbc6854d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16a6f7335bd349ceaa0cba205418bbae"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b91dcc8b2d7d465a8df095008c84546b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | loss=0.6443 | AUC=0.5612 | H@1=0.0778 | H@5=0.1888 | H@10=0.2590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 7:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "239a7c2a7a3b4172a5b1d1fee7a2d9c7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e6c0b554d804883a4dc70dc6ba56413"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c8567b02dcb41fd931b6591beedd97c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | loss=0.6461 | AUC=0.5648 | H@1=0.0569 | H@5=0.1651 | H@10=0.2324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 8:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4474c48e53d74bd5a096132e1a915966"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b43bab927f94ad48a9c571c5853d599"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "607e53932d6b4399af68fbdb0013523e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | loss=0.6435 | AUC=0.5561 | H@1=0.0731 | H@5=0.1869 | H@10=0.2543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 9:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "072ffd62d13d46a9981d12c76901fa09"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e457162481d44e548a118e14a2f3dbc9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c2afd1d46cf411ca4ec4495249f7f89"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | loss=0.6406 | AUC=0.5556 | H@1=0.0674 | H@5=0.1546 | H@10=0.2144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 10:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65e2a67d2304497a9d263e5dbc3b73dc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0ddd8c947264a81a34d07b698e74790"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe58945236974e7b822e6b3e89251907"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | loss=0.6411 | AUC=0.5350 | H@1=0.0787 | H@5=0.1698 | H@10=0.2372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 11:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fc4739f09994a67a0d1fda8696abd5a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "897ea29e46b04546916c1fe7d994adc5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62bc6eb253884118b076c852cd05deb3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | loss=0.6423 | AUC=0.5547 | H@1=0.0493 | H@5=0.1309 | H@10=0.1945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 12:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "903605f72fe54e13aa15034bd2983c04"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be9105fb40904f53a865987789dbbdc9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5a14c957a874b019cd77d75043ba450"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | loss=0.6403 | AUC=0.5634 | H@1=0.0674 | H@5=0.1613 | H@10=0.2343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 13:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4ead2b971d04f41910b4a5b89e4fced"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b2af72fddc44f179dd8539dc9298d9c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdc0592828c94153bd92adf0caf607f8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | loss=0.6398 | AUC=0.5613 | H@1=0.0778 | H@5=0.1565 | H@10=0.2211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train 14:   0%|          | 0/132 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f425aef88b094bffb86d8ff3d694db55"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval AUC (typed):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89cfbe7dbad94fda993fdd43429da77a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Eval Hits (tail):   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a6a591ff9984f1a996f13050646dff1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | loss=0.6382 | AUC=0.5514 | H@1=0.0550 | H@5=0.1366 | H@10=0.1898\n",
      "Early stopping at epoch 14 (patience=10).\n",
      "Restored best model from epoch 4 | AUC=0.5590 | Hits@10=0.2638\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "11257874af2df890"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311 WN18RR",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
